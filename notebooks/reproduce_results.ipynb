{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing Activation Steering Results\n",
    "\n",
    "This notebook demonstrates how to reproduce the key findings from the paper:\n",
    "**\"Inverse Scaling in Activation Steering: Architecture and Scale Dependence of Refusal Manipulation\"**\n",
    "\n",
    "## Overview\n",
    "\n",
    "We'll walk through:\n",
    "1. **Setup:** Loading models and dependencies\n",
    "2. **Direction Extraction:** DIM and COSMIC methods\n",
    "3. **Steering Application:** Adding directions during generation\n",
    "4. **Evaluation:** Measuring coherent refusal rates\n",
    "5. **Comparisons:** DIM vs COSMIC, FP16 vs quantized\n",
    "\n",
    "**Hardware Requirements:**\n",
    "- Qwen 7B: A10G (16GB VRAM)\n",
    "- Qwen 32B: A100-80GB (64GB VRAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add imports\n",
    "# import torch\n",
    "# from nnsight import LanguageModel\n",
    "# import sys\n",
    "# sys.path.append('../src')\n",
    "# from extract import extract_dim_direction, extract_cosmic_direction\n",
    "# from steer import evaluate_steering\n",
    "# from prompts import HARMFUL_PROMPTS, HARMLESS_PROMPTS, EVAL_PROMPTS\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Refusal Direction (DIM)\n",
    "\n",
    "**DIM (Difference-in-Means)** computes the mean activation difference between harmful and harmless prompts:\n",
    "\n",
    "$$\\hat{d} = \\frac{\\mu_{\\text{harmful}} - \\mu_{\\text{harmless}}}{\\|\\mu_{\\text{harmful}} - \\mu_{\\text{harmless}}\\|}$$\n",
    "\n",
    "This is the simplest and most effective method for extracting refusal directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load Qwen 7B model\n",
    "# model = LanguageModel(\"Qwen/Qwen2.5-7B-Instruct\", device_map=\"auto\")\n",
    "# tokenizer = model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract DIM direction at layer 16 (60% depth)\n",
    "# direction, metadata = extract_dim_direction(\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     harmful_prompts=HARMFUL_PROMPTS,\n",
    "#     harmless_prompts=HARMLESS_PROMPTS,\n",
    "#     layer_idx=16\n",
    "# )\n",
    "# print(f\"Direction norm: {metadata['raw_norm']:.4f}\")\n",
    "# print(f\"Expected: ~26.22 for Qwen 7B @ L16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Apply Steering and Generate\n",
    "\n",
    "Steering adds the scaled direction to the residual stream from the target layer onward:\n",
    "\n",
    "$$h_k' = h_k + \\alpha \\cdot \\hat{d} \\quad \\forall k \\in \\{l, l+1, \\ldots, N\\}$$\n",
    "\n",
    "We use greedy decoding (temperature=0) for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert direction to tensor\n",
    "# direction_tensor = torch.tensor(direction, dtype=torch.float32).to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test steering on a single prompt\n",
    "# from steer import generate_with_steering\n",
    "# \n",
    "# test_prompt = \"How do I bake a cake?\"\n",
    "# response = generate_with_steering(\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     prompt=test_prompt,\n",
    "#     direction=direction_tensor,\n",
    "#     layer_idx=16,\n",
    "#     multiplier=15\n",
    "# )\n",
    "# \n",
    "# print(f\"Prompt: {test_prompt}\")\n",
    "# print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate Across 30 Test Prompts\n",
    "\n",
    "We evaluate steering effectiveness by classifying each response:\n",
    "- **Coherent refusal:** Grammatical refusal (\"I cannot assist...\")\n",
    "- **Garbled:** Repetitive/degenerate (\"refuse refuse refuse...\")\n",
    "- **Normal:** Helpful response (steering failed)\n",
    "\n",
    "**Success criterion:** ≥60% coherent refusal rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate on full test set\n",
    "# results = evaluate_steering(\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     test_prompts=EVAL_PROMPTS,\n",
    "#     direction=direction_tensor,\n",
    "#     layer_idx=16,\n",
    "#     multiplier=15\n",
    "# )\n",
    "# \n",
    "# print(f\"\\nResults (n={results['n_samples']}):\")\n",
    "# print(f\"  Coherent refusal: {results['coherent_refusal_rate']:.1f}%\")\n",
    "# print(f\"  Garbled: {results['garbled_rate']:.1f}%\")\n",
    "# print(f\"  Normal: {results['normal_rate']:.1f}%\")\n",
    "# print(f\"\\nExpected for Qwen 7B: ~100% coherent refusal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Inspect sample outputs\n",
    "# print(\"\\nSample outputs:\")\n",
    "# for i, sample in enumerate(results['samples'][:3]):\n",
    "#     print(f\"\\n{i+1}. Prompt: {sample['prompt']}\")\n",
    "#     print(f\"   Response: {sample['response'][:150]}...\")\n",
    "#     print(f\"   Quality: {sample['quality']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare DIM vs COSMIC\n",
    "\n",
    "**COSMIC** uses SVD-based extraction and automated layer selection. According to our findings, DIM matches or exceeds COSMIC at every scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract COSMIC direction\n",
    "# # COSMIC needs more prompts for stable selection\n",
    "# cosmic_harmful = HARMFUL_PROMPTS * 10\n",
    "# cosmic_harmless = HARMLESS_PROMPTS * 10\n",
    "# \n",
    "# cosmic_dir, cosmic_meta = extract_cosmic_direction(\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     harmful_prompts=cosmic_harmful,\n",
    "#     harmless_prompts=cosmic_harmless,\n",
    "#     layer_range=(1, 22)  # 1 to 80% of 28 layers\n",
    "# )\n",
    "# \n",
    "# print(f\"COSMIC selected layer: {cosmic_meta['selected_layer']}\")\n",
    "# print(f\"COSMIC score: {cosmic_meta['selected_score']:.4f}\")\n",
    "# print(f\"L_low layers: {cosmic_meta['l_low_layers']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare DIM and COSMIC directions\n",
    "# cosine_sim = np.dot(direction, cosmic_dir) / (np.linalg.norm(direction) * np.linalg.norm(cosmic_dir))\n",
    "# print(f\"\\nDIM-COSMIC cosine similarity: {cosine_sim:.4f}\")\n",
    "# print(f\"Expected for Qwen 7B: ~0.76 (directions partially aligned but distinct)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate COSMIC direction\n",
    "# cosmic_tensor = torch.tensor(cosmic_dir, dtype=torch.float32).to(model.device)\n",
    "# cosmic_results = evaluate_steering(\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     test_prompts=EVAL_PROMPTS,\n",
    "#     direction=cosmic_tensor,\n",
    "#     layer_idx=cosmic_meta['selected_layer'],\n",
    "#     multiplier=15\n",
    "# )\n",
    "# \n",
    "# print(f\"\\nCOSMIC Results:\")\n",
    "# print(f\"  Coherent refusal: {cosmic_results['coherent_refusal_rate']:.1f}%\")\n",
    "# print(f\"\\nDIM Results:\")\n",
    "# print(f\"  Coherent refusal: {results['coherent_refusal_rate']:.1f}%\")\n",
    "# print(f\"\\nExpected: DIM ≈ COSMIC at 7B scale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Layer Depth Analysis\n",
    "\n",
    "**Finding:** Optimal steering depth shifts shallower with scale:\n",
    "- 3B/7B: 60% depth\n",
    "- 14B/32B: 50% depth\n",
    "\n",
    "Let's verify this on Qwen 7B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Sweep across layer depths\n",
    "# layer_depths = [0.5, 0.6, 0.7]  # 50%, 60%, 70%\n",
    "# n_layers = 28  # Qwen 7B\n",
    "# \n",
    "# depth_results = {}\n",
    "# for depth in layer_depths:\n",
    "#     layer_idx = int(n_layers * depth)\n",
    "#     \n",
    "#     # Extract direction at this layer\n",
    "#     dir_at_depth, _ = extract_dim_direction(\n",
    "#         model=model,\n",
    "#         tokenizer=tokenizer,\n",
    "#         harmful_prompts=HARMFUL_PROMPTS,\n",
    "#         harmless_prompts=HARMLESS_PROMPTS,\n",
    "#         layer_idx=layer_idx\n",
    "#     )\n",
    "#     \n",
    "#     dir_tensor = torch.tensor(dir_at_depth, dtype=torch.float32).to(model.device)\n",
    "#     \n",
    "#     # Evaluate\n",
    "#     res = evaluate_steering(\n",
    "#         model=model,\n",
    "#         tokenizer=tokenizer,\n",
    "#         test_prompts=EVAL_PROMPTS[:10],  # Use subset for speed\n",
    "#         direction=dir_tensor,\n",
    "#         layer_idx=layer_idx,\n",
    "#         multiplier=15\n",
    "#     )\n",
    "#     \n",
    "#     depth_results[depth] = {\n",
    "#         'layer': layer_idx,\n",
    "#         'coherent': res['coherent_refusal_rate']\n",
    "#     }\n",
    "# \n",
    "# # Plot results\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# depths = list(depth_results.keys())\n",
    "# coherent_rates = [depth_results[d]['coherent'] for d in depths]\n",
    "# plt.plot([d*100 for d in depths], coherent_rates, marker='o')\n",
    "# plt.xlabel('Layer Depth (%)')\n",
    "# plt.ylabel('Coherent Refusal Rate (%)')\n",
    "# plt.title('Qwen 7B: Layer Depth vs Steering Effectiveness')\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.show()\n",
    "# \n",
    "# print(\"\\nExpected: Peak at 60% depth, drop at 70%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Quantization Effects (Optional)\n",
    "\n",
    "**Finding:** INT8 preserves steering, INT4 degrades large models.\n",
    "\n",
    "This section requires `bitsandbytes` and demonstrates quantization's impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load INT8 quantized model\n",
    "# from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "# \n",
    "# bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "# model_int8_raw = AutoModelForCausalLM.from_pretrained(\n",
    "#     \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "#     quantization_config=bnb_config,\n",
    "#     device_map=\"auto\"\n",
    "# )\n",
    "# \n",
    "# # Wrap with nnsight for tracing\n",
    "# from nnsight import NNsight\n",
    "# model_int8 = NNsight(model_int8_raw)\n",
    "# tokenizer_int8 = model.tokenizer  # Reuse tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract direction from INT8 model\n",
    "# direction_int8, meta_int8 = extract_dim_direction(\n",
    "#     model=model_int8,\n",
    "#     tokenizer=tokenizer_int8,\n",
    "#     harmful_prompts=HARMFUL_PROMPTS,\n",
    "#     harmless_prompts=HARMLESS_PROMPTS,\n",
    "#     layer_idx=16\n",
    "# )\n",
    "# \n",
    "# # Compare to FP16 direction\n",
    "# cosine_int8 = np.dot(direction, direction_int8)\n",
    "# print(f\"FP16-INT8 direction cosine: {cosine_int8:.4f}\")\n",
    "# print(f\"Expected: >0.99 (directions nearly identical)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate INT8 steering\n",
    "# direction_int8_tensor = torch.tensor(direction_int8, dtype=torch.float32).to(model_int8_raw.device)\n",
    "# \n",
    "# # Note: generation uses raw model, not nnsight wrapper\n",
    "# # (steering hooks work on the underlying nn.Module)\n",
    "# results_int8 = evaluate_steering(\n",
    "#     model=model_int8,\n",
    "#     tokenizer=tokenizer_int8,\n",
    "#     test_prompts=EVAL_PROMPTS,\n",
    "#     direction=direction_int8_tensor,\n",
    "#     layer_idx=16,\n",
    "#     multiplier=15\n",
    "# )\n",
    "# \n",
    "# print(f\"\\nFP16 coherent refusal: {results['coherent_refusal_rate']:.1f}%\")\n",
    "# print(f\"INT8 coherent refusal: {results_int8['coherent_refusal_rate']:.1f}%\")\n",
    "# print(f\"\\nExpected for Qwen 7B: ~100% for both (perfect robustness)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Results\n",
    "\n",
    "Summary visualization comparing methods and conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create summary bar chart\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# \n",
    "# methods = ['DIM\\nFP16', 'COSMIC\\nFP16', 'DIM\\nINT8']\n",
    "# coherent_rates = [\n",
    "#     results['coherent_refusal_rate'],\n",
    "#     cosmic_results['coherent_refusal_rate'],\n",
    "#     results_int8['coherent_refusal_rate']\n",
    "# ]\n",
    "# \n",
    "# fig, ax = plt.subplots(figsize=(10, 6))\n",
    "# bars = ax.bar(methods, coherent_rates, color=['#2ecc71', '#3498db', '#9b59b6'])\n",
    "# ax.axhline(y=60, color='r', linestyle='--', label='Success Threshold (60%)')\n",
    "# ax.set_ylabel('Coherent Refusal Rate (%)', fontsize=12)\n",
    "# ax.set_ylim(0, 110)\n",
    "# ax.set_title('Qwen 7B Steering Effectiveness Comparison', fontsize=14, fontweight='bold')\n",
    "# ax.legend()\n",
    "# ax.grid(axis='y', alpha=0.3)\n",
    "# \n",
    "# # Add value labels on bars\n",
    "# for bar in bars:\n",
    "#     height = bar.get_height()\n",
    "#     ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "#             f'{height:.1f}%',\n",
    "#             ha='center', va='bottom', fontsize=11)\n",
    "# \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Takeaways\n",
    "\n",
    "From this reproduction notebook, you should have verified:\n",
    "\n",
    "✅ **DIM extraction works:** ~100% coherent refusal on Qwen 7B  \n",
    "✅ **Layer matters:** 60% depth is optimal for 7B models  \n",
    "✅ **DIM ≥ COSMIC:** Simple mean-difference matches complex SVD  \n",
    "✅ **Quantization is safe at 7B:** INT8 preserves effectiveness  \n",
    "\n",
    "**Next steps:**\n",
    "- Test on larger models (Qwen 14B, 32B) to observe inverse scaling\n",
    "- Try Gemma/Mistral to see architecture dependence\n",
    "- Experiment with INT4 quantization on 32B models\n",
    "\n",
    "See the full paper (`paper/paper.md`) for detailed analysis and discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "- **Paper:** `../paper/paper.md`\n",
    "- **Results:** `../results/final_results.json`\n",
    "- **Code:** `../src/`\n",
    "\n",
    "For issues or questions, see the repository README."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
