\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{turner2023activation,zou2023representation}
\citation{ouyang2022training}
\citation{arditi2024refusal}
\citation{zou2023representation}
\citation{panickssery2023steering}
\citation{jorgensen2023mean}
\citation{arditi2024refusal}
\citation{siu2025cosmic}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{fiottokaufman2024nnsight}
\citation{turner2023activation}
\citation{zou2023representation}
\citation{li2023inference}
\citation{panickssery2023steering}
\citation{arditi2024refusal}
\@writefile{toc}{\contentsline {section}{\numberline {2}Quick Tour of Findings}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Background \& Related Work}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Activation Steering Foundations}{3}{subsection.3.1}\protected@file@percent }
\citation{arditi2024refusal}
\citation{jorgensen2023mean}
\citation{panickssery2023steering}
\citation{zou2023representation}
\citation{siu2025cosmic}
\citation{ouyang2022training}
\citation{zou2023gcg}
\citation{lermen2023lora}
\citation{wei2024brittleness}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Direction Extraction Methods: DIM, COSMIC, and the SVD Lineage}{4}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Refusal Mechanisms in LLMs}{4}{subsection.3.3}\protected@file@percent }
\citation{beaglehole2025universal}
\citation{dettmers2022int8}
\citation{frantar2022gptq}
\citation{lin2024awq}
\citation{turner2023activation,panickssery2023steering,siu2025cosmic}
\citation{arditi2024refusal}
\citation{beaglehole2025universal}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Quantization Effects on Representations}{5}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}The Gap in the Literature}{5}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Methods}{5}{section.4}\protected@file@percent }
\newlabel{sec:methods}{{4}{5}{Methods}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Models}{5}{subsection.4.1}\protected@file@percent }
\citation{arditi2024refusal}
\citation{panickssery2023steering}
\citation{zou2023representation}
\citation{jorgensen2023mean}
\citation{siu2025cosmic}
\citation{fiottokaufman2024nnsight}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Model configurations.}}{6}{table.1}\protected@file@percent }
\newlabel{tab:models}{{1}{6}{Model configurations}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Direction Extraction}{6}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Steering}{7}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Evaluation}{7}{subsection.4.4}\protected@file@percent }
\citation{dettmers2022int8}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Quantization Setup}{8}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{8}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Architecture Dependence}{8}{subsection.5.1}\protected@file@percent }
\newlabel{sec:architecture}{{5.1}{8}{Architecture Dependence}{subsection.5.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Architecture comparison at matched conditions.}}{9}{table.2}\protected@file@percent }
\newlabel{tab:architecture}{{2}{9}{Architecture comparison at matched conditions}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Inverse Size Scaling}{9}{subsection.5.2}\protected@file@percent }
\newlabel{sec:inverse-scaling}{{5.2}{9}{Inverse Size Scaling}{subsection.5.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Qwen family scaling (DIM @ 15$\times $).}}{9}{table.3}\protected@file@percent }
\newlabel{tab:qwen-scaling}{{3}{9}{Qwen family scaling (DIM @ 15$\times $)}{table.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Gemma family scaling (DIM @ 25$\times $).}}{10}{table.4}\protected@file@percent }
\newlabel{tab:gemma-scaling}{{4}{10}{Gemma family scaling (DIM @ 25$\times $)}{table.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Inverse scaling of steering effectiveness. Coherent refusal rates decline monotonically with model scale across both Qwen (100\% at 3B/7B $\to $ 90\% at 14B $\to $ 77\% at 32B) and Gemma (100\% at 2B $\to $ 97\% at 9B $\to $ 0\% at 27B) families.}}{10}{figure.1}\protected@file@percent }
\newlabel{fig:inverse-scaling}{{1}{10}{Inverse scaling of steering effectiveness. Coherent refusal rates decline monotonically with model scale across both Qwen (100\% at 3B/7B $\to $ 90\% at 14B $\to $ 77\% at 32B) and Gemma (100\% at 2B $\to $ 97\% at 9B $\to $ 0\% at 27B) families}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Layer Depth Heuristic}{10}{subsection.5.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Qwen layer profiles (DIM @ 15$\times $).}}{11}{table.5}\protected@file@percent }
\newlabel{tab:qwen-layers}{{5}{11}{Qwen layer profiles (DIM @ 15$\times $)}{table.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Gemma layer profiles (DIM @ 25$\times $).}}{11}{table.6}\protected@file@percent }
\newlabel{tab:gemma-layers}{{6}{11}{Gemma layer profiles (DIM @ 25$\times $)}{table.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}DIM $\geq $ COSMIC}{11}{subsection.5.4}\protected@file@percent }
\newlabel{sec:dim-cosmic}{{5.4}{11}{DIM $\geq $ COSMIC}{subsection.5.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces DIM vs. COSMIC comparison (n = 50 prompts).}}{11}{table.7}\protected@file@percent }
\newlabel{tab:dim-cosmic}{{7}{11}{DIM vs. COSMIC comparison (n = 50 prompts)}{table.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Optimal steering depth shifts shallower with scale. Qwen models show peak effectiveness at 60\% depth (3B/7B) declining to 50\% (14B/32B). Gemma models require shallower intervention (30--40\% depth) compared to Qwen.}}{12}{figure.2}\protected@file@percent }
\newlabel{fig:layer-profiles}{{2}{12}{Optimal steering depth shifts shallower with scale. Qwen models show peak effectiveness at 60\% depth (3B/7B) declining to 50\% (14B/32B). Gemma models require shallower intervention (30--40\% depth) compared to Qwen}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Quantization Robustness}{12}{subsection.5.5}\protected@file@percent }
\newlabel{sec:quantization}{{5.5}{12}{Quantization Robustness}{subsection.5.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Quantization robustness (n = 30).}}{12}{table.8}\protected@file@percent }
\newlabel{tab:quantization}{{8}{12}{Quantization robustness (n = 30)}{table.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces DIM matches or exceeds COSMIC at every scale. Both methods achieve 100\% at 3B and 90\% at 14B. At 32B, DIM achieves 60\% coherent refusal while COSMIC's automated layer selection yields only 10\% (Fisher's exact $p < 0.001$).}}{13}{figure.3}\protected@file@percent }
\newlabel{fig:dim-cosmic}{{3}{13}{DIM matches or exceeds COSMIC at every scale. Both methods achieve 100\% at 3B and 90\% at 14B. At 32B, DIM achieves 60\% coherent refusal while COSMIC's automated layer selection yields only 10\% (Fisher's exact $p < 0.001$)}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Multiplier Sensitivity at Scale}{13}{subsection.5.6}\protected@file@percent }
\newlabel{sec:multiplier}{{5.6}{13}{Multiplier Sensitivity at Scale}{subsection.5.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Quantization robustness is scale-dependent. Qwen 7B maintains 100\% coherent refusal across FP16, INT8, and INT4. Qwen 32B shows degradation at INT4 (77\% $\to $ 57\%), despite direction cosine similarity of 0.974.}}{14}{figure.4}\protected@file@percent }
\newlabel{fig:quantization}{{4}{14}{Quantization robustness is scale-dependent. Qwen 7B maintains 100\% coherent refusal across FP16, INT8, and INT4. Qwen 32B shows degradation at INT4 (77\% $\to $ 57\%), despite direction cosine similarity of 0.974}{figure.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Multiplier sensitivity at Qwen 32B (n = 50).}}{14}{table.9}\protected@file@percent }
\newlabel{tab:multiplier}{{9}{14}{Multiplier sensitivity at Qwen 32B (n = 50)}{table.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}The Mistral Anomaly}{14}{section.6}\protected@file@percent }
\newlabel{sec:mistral}{{6}{14}{The Mistral Anomaly}{section.6}{}}
\citation{arditi2024refusal}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Multiplier sensitivity at Qwen 32B. The effective window is narrow: 15$\times $ produces 60\% coherent refusal, 20$\times $ drops to 20\%, and 25$\times $ causes coherence collapse (90\% garbled). Smaller models tolerate 15$\times $--25$\times $ without degradation.}}{15}{figure.5}\protected@file@percent }
\newlabel{fig:multiplier}{{5}{15}{Multiplier sensitivity at Qwen 32B. The effective window is narrow: 15$\times $ produces 60\% coherent refusal, 20$\times $ drops to 20\%, and 25$\times $ causes coherence collapse (90\% garbled). Smaller models tolerate 15$\times $--25$\times $ without degradation}{figure.5}{}}
\citation{elhage2022toy}
\@writefile{toc}{\contentsline {section}{\numberline {7}Tooling Sensitivity as a Methodological Finding}{16}{section.7}\protected@file@percent }
\newlabel{sec:tooling}{{7}{16}{Tooling Sensitivity as a Methodological Finding}{section.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Discussion}{16}{section.8}\protected@file@percent }
\newlabel{sec:discussion}{{8}{16}{Discussion}{section.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}What Inverse Scaling Tells Us About Refusal Geometry}{16}{subsection.8.1}\protected@file@percent }
\citation{wei2024brittleness}
\citation{beaglehole2025universal}
\citation{beaglehole2025universal}
\citation{marks2023geometry}
\citation{arditi2024refusal}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Why Simple Beats Complex (and When It Won't)}{17}{subsection.8.2}\protected@file@percent }
\citation{beaglehole2025universal}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}What Transfer Tells Us About Refusal Geometry}{18}{subsection.8.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Mechanistic Hypotheses}{18}{section.9}\protected@file@percent }
\citation{arditi2024refusal}
\@writefile{toc}{\contentsline {section}{\numberline {10}Implications for Safety}{19}{section.10}\protected@file@percent }
\citation{beaglehole2025universal}
\@writefile{toc}{\contentsline {section}{\numberline {11}Cross-Model Transfer of Refusal Directions}{20}{section.11}\protected@file@percent }
\newlabel{sec:transfer}{{11}{20}{Cross-Model Transfer of Refusal Directions}{section.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1}Transfer Protocol}{20}{subsection.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2}Same-Family Transfer (Qwen 14B $\leftrightarrow $ 32B)}{20}{subsection.11.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Transfer of DIM refusal directions. TE = transfer efficiency (ratio of transferred coherent rate to target self-control rate). Cross-cos = cosine similarity between source and target directions in matched dimensionality. All results: $n = 30$, greedy decoding, seed 42 (same-family replicated on seed 43 with identical results).}}{21}{table.10}\protected@file@percent }
\newlabel{tab:transfer}{{10}{21}{Transfer of DIM refusal directions. TE = transfer efficiency (ratio of transferred coherent rate to target self-control rate). Cross-cos = cosine similarity between source and target directions in matched dimensionality. All results: $n = 30$, greedy decoding, seed 42 (same-family replicated on seed 43 with identical results)}{table.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3}Cross-Family Transfer (Qwen 7B $\leftrightarrow $ Gemma 9B)}{21}{subsection.11.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.4}Interpretation}{21}{subsection.11.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.5}Scope and Caveats}{21}{subsection.11.5}\protected@file@percent }
\citation{arditi2024refusal}
\@writefile{toc}{\contentsline {section}{\numberline {12}Limitations}{22}{section.12}\protected@file@percent }
\newlabel{sec:limitations}{{12}{22}{Limitations}{section.12}{}}
\citation{templeton2024scaling}
\bibstyle{plainnat}
\bibdata{references}
\bibcite{arditi2024refusal}{{1}{2024}{{Arditi et~al.}}{{Arditi, Obeso, Syed, Paleka, Rimsky, Gurnee, and Nanda}}}
\@writefile{toc}{\contentsline {section}{\numberline {13}Conclusion}{23}{section.13}\protected@file@percent }
\bibcite{beaglehole2025universal}{{2}{2025}{{Beaglehole et~al.}}{{Beaglehole, Radhakrishnan, Boix-Adsera, et~al.}}}
\bibcite{dettmers2022int8}{{3}{2022}{{Dettmers et~al.}}{{Dettmers, Lewis, Belkada, and Zettlemoyer}}}
\bibcite{elhage2022toy}{{4}{2022}{{Elhage et~al.}}{{Elhage, Hume, Olsson, Schiefer, Henighan, Kravec, Hatfield-Dodds, Lasenby, Drain, Chen, Grosse, McCandlish, Kaplan, Amodei, Wattenberg, and Olah}}}
\bibcite{fiottokaufman2024nnsight}{{5}{2024}{{Fiotto-Kaufman et~al.}}{{Fiotto-Kaufman, Loftus, Todd, Brinkmann, Pal, Troitskii, Ripa, Belfki, Rager, Juang, Mueller, Marks, Sharma, Lucchetti, Prakash, Brodley, and Bau}}}
\bibcite{frantar2022gptq}{{6}{2023}{{Frantar et~al.}}{{Frantar, Ashkboos, Hoefler, and Alistarh}}}
\bibcite{jorgensen2023mean}{{7}{2023}{{Jorgensen et~al.}}{{Jorgensen, Cope, Schoots, and Sherburn}}}
\bibcite{lermen2023lora}{{8}{2023}{{Lermen et~al.}}{{Lermen, Rogers-Smith, and Ladish}}}
\bibcite{li2023inference}{{9}{2023}{{Li et~al.}}{{Li, Patel, Vi{\'e}gas, Pfister, and Wattenberg}}}
\bibcite{lin2024awq}{{10}{2024}{{Lin et~al.}}{{Lin, Tang, Tang, Yang, Chen, Wang, Xiao, Dang, Gan, and Han}}}
\bibcite{marks2023geometry}{{11}{2023}{{Marks and Tegmark}}{{}}}
\bibcite{ouyang2022training}{{12}{2022}{{Ouyang et~al.}}{{Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin, Zhang, Agarwal, Slama, Ray, Schulman, Hilton, Kelton, Miller, Simens, Askell, Welinder, Christiano, Leike, and Lowe}}}
\bibcite{panickssery2023steering}{{13}{2023}{{Panickssery et~al.}}{{Panickssery, Gabrieli, Schulz, Tong, Hubinger, and Turner}}}
\bibcite{siu2025cosmic}{{14}{2025}{{Siu et~al.}}{{Siu, Crispino, Yu, Pan, Wang, Liu, et~al.}}}
\bibcite{templeton2024scaling}{{15}{2024}{{Templeton et~al.}}{{Templeton, Conerly, Marcus, Lindsey, Bricken, Chen, Pearce, Citro, Ameisen, Jones, Cunningham, Turner, McDougall, MacDiarmid, Tamkin, Durmus, Hume, Mosconi, Freeman, Sumers, Rees, Batson, Jermyn, Carter, Olah, and Henighan}}}
\bibcite{turner2023activation}{{16}{2023}{{Turner et~al.}}{{Turner, Thiergart, Leech, Udell, Vazquez, Mini, and MacDiarmid}}}
\bibcite{wei2024brittleness}{{17}{2024}{{Wei et~al.}}{{Wei, Huang, Huang, Xie, Qi, Xia, Mittal, Wang, and Henderson}}}
\bibcite{zou2023representation}{{18}{2023{a}}{{Zou et~al.}}{{Zou, Phan, Chen, Campbell, Guo, Ren, Pan, Yin, Mazeika, Dombrowski, Goel, Li, Byun, Wang, Mallen, Basart, Koyejo, Song, Fredrikson, Kolter, and Hendrycks}}}
\bibcite{zou2023gcg}{{19}{2023{b}}{{Zou et~al.}}{{Zou, Wang, Carlini, Nasr, Kolter, and Fredrikson}}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Contrastive Prompt Sets}{25}{appendix.A}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Harmful Prompts (Direction Extraction)}{25}{subsection.A.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Harmless Prompts (Direction Extraction)}{26}{subsection.A.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Test Prompts (Evaluation)}{26}{subsection.A.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Layer-by-layer coherent refusal profiles across Qwen and Gemma families. Optimal depths shift from 60\% (Qwen 3B/7B) to 50\% (Qwen 14B/32B) and 30--40\% (Gemma 2B/9B). Steering at 70\% depth fails catastrophically for larger Qwen models.}}{27}{figure.6}\protected@file@percent }
\newlabel{fig:layer-profiles-detail}{{6}{27}{Layer-by-layer coherent refusal profiles across Qwen and Gemma families. Optimal depths shift from 60\% (Qwen 3B/7B) to 50\% (Qwen 14B/32B) and 30--40\% (Gemma 2B/9B). Steering at 70\% depth fails catastrophically for larger Qwen models}{figure.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Complete Results Tables}{27}{appendix.B}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}Qwen 2.5 Size Sweep --- Full Layer Profiles}{27}{subsection.B.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Qwen 2.5-3B-Instruct (36 layers)}}{27}{table.11}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces Qwen 2.5-7B-Instruct (28 layers)}}{27}{table.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}Gemma 2 Size Sweep --- Full Layer Profiles}{27}{subsection.B.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {13}{\ignorespaces Qwen 2.5-14B-Instruct (48 layers)}}{28}{table.13}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {14}{\ignorespaces Qwen 2.5-32B-Instruct (64 layers)}}{28}{table.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}Direction Norms and Steering Success}{28}{subsection.B.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B.4}Mistral 7B --- Architecture Failure}{28}{subsection.B.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {C}Example Steered Outputs}{28}{appendix.C}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}Coherent Refusal Examples}{28}{subsection.C.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}Garbled Output Examples}{28}{subsection.C.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {15}{\ignorespaces Gemma 2-2B-IT (26 layers)}}{29}{table.15}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {16}{\ignorespaces Gemma 2-9B-IT (42 layers)}}{29}{table.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3}Normal (Unsteered) Output Examples}{29}{subsection.C.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {17}{\ignorespaces Gemma 2-27B-IT (46 layers)}}{30}{table.17}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Direction norm vs coherent refusal rate across models. Norms in the 20--90 range predict successful steering. Gemma 27B's extreme norms (350+) coincide with complete steering failure (0\% coherent refusal), consistent with the hypothesis that refusal becomes too distributed for single-direction capture at scale.}}{30}{figure.7}\protected@file@percent }
\newlabel{fig:norm-refusal}{{7}{30}{Direction norm vs coherent refusal rate across models. Norms in the 20--90 range predict successful steering. Gemma 27B's extreme norms (350+) coincide with complete steering failure (0\% coherent refusal), consistent with the hypothesis that refusal becomes too distributed for single-direction capture at scale}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Geometric vs functional preservation under quantization. Direction cosines remain high ($\sim $0.97) across FP16/INT8/INT4 at both 7B and 32B, yet functional performance diverges dramatically at 32B (0pp drop at 7B, 20pp drop at 32B for INT4). The quantized directions point in nearly the same direction, but the quantized model's response differs.}}{31}{figure.8}\protected@file@percent }
\newlabel{fig:quant-divergence}{{8}{31}{Geometric vs functional preservation under quantization. Direction cosines remain high ($\sim $0.97) across FP16/INT8/INT4 at both 7B and 32B, yet functional performance diverges dramatically at 32B (0pp drop at 7B, 20pp drop at 32B for INT4). The quantized directions point in nearly the same direction, but the quantized model's response differs}{figure.8}{}}
\gdef \@abspage@last{31}
